# ğŸš€ Fraud Detection System

A comprehensive real-time fraud detection system using machine learning, Kafka streaming, Spark processing, and Docker microservices.

## ğŸ“‹ Features

- **ML-Based Fraud Detection**: RandomForest classifier with SMOTE handling for imbalanced data
- **Real-Time Streaming**: Kafka producer/consumer for transaction streaming
- **Spark Processing**: Distributed processing of transaction streams
- **Alert Service**: Real-time fraud alerts with risk scoring
- **Web Dashboard**: Interactive dashboard for monitoring system health and alerts
- **Microservices Architecture**: Containerized services with Docker and Docker Compose

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Fraud Detection System                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚  Producer    â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚    Kafka     â”‚                     â”‚
â”‚  â”‚  (Simulator) â”‚       â”‚  (Broker)    â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                               â”‚                               â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚                    â”‚                     â”‚                    â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚            â”‚  Spark Job   â”‚      â”‚  ML Service   â”‚            â”‚
â”‚            â”‚ (Processing) â”‚      â”‚  (Scoring)    â”‚            â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                    â”‚                     â”‚                    â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                               â”‚                               â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚                        â”‚   Alert     â”‚                        â”‚
â”‚                        â”‚  Service    â”‚                        â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                               â”‚                               â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚                        â”‚  Web UI &   â”‚                        â”‚
â”‚                        â”‚ Dashboard   â”‚                        â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Services

| Service | Port | Purpose |
|---------|------|---------|
| ML Service | 5000 | Fraud prediction endpoint |
| Alert Service | 5001 | Alert management and notifications |
| Web UI | 8000 | Dashboard for monitoring |
| Kafka | 9092 | Message broker |
| Zookeeper | 2181 | Kafka coordination |

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- Docker & Docker Compose
- bash

### Setup Instructions

#### 1. Clone and Navigate

```bash
cd /path/to/Fraud_Detection_System-main
```

#### 2. Create Virtual Environment

```bash
python3.10 -m venv venv
source venv/bin/activate
```

#### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

#### 4. Generate Training Data

```bash
python data/generate_data.py
```

This creates:
- `data/raw/transactions_train.csv` (8,000 transactions)
- `data/raw/transactions_test.csv` (2,000 transactions)

#### 5. Train ML Model

```bash
python ml_model/model_training.py
```

This creates:
- `ml_model/fraud_model.pkl` (trained RandomForest model)
- `ml_model/feature_engineer.pkl` (feature engineering pipeline)

#### 6. Start All Services

```bash
./scripts/run_all.sh
```

Or start services individually:

**ML Service** (Terminal 1):
```bash
python ml_service/app.py
```

**Alert Service** (Terminal 2):
```bash
python alert_service/alert_app.py
```

**Web UI** (Terminal 3):
```bash
python web_ui/app.py
```

**Producer** (Terminal 4):
```bash
python kafka_streaming/producer.py
```

#### 7. Access the System

- **Dashboard**: http://localhost:8000
- **ML Service Health**: http://localhost:5000/health
- **Alert Service Health**: http://localhost:5001/health
- **Recent Alerts**: http://localhost:5001/alerts/recent

### Using Docker

#### Build and Start All Services

```bash
docker-compose up --build
```

#### Stop Services

```bash
docker-compose down
```

## ğŸ“Š Usage Examples

### Simulate Transactions

```bash
python scripts/simulate_transactions.py --max 50
```

### Check Service Health

```bash
curl http://localhost:5000/health
curl http://localhost:5001/health
```

### Get Recent Alerts

```bash
curl http://localhost:5001/alerts/recent?limit=5
```

### Get Alert Summary

```bash
curl http://localhost:5001/alerts/summary
```

### Single Transaction Prediction

```bash
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "transaction_id": "TXN123456",
    "amount": 1500.00,
    "amount_log": 7.31,
    "latitude": 40.7128,
    "longitude": -74.0060,
    "hour": 14,
    "day_of_week": 2,
    "is_weekend": 0,
    "is_night": 0,
    "transaction_type": "online"
  }'
```

### Batch Prediction

```bash
curl -X POST http://localhost:5000/batch-predict \
  -H "Content-Type: application/json" \
  -d '[
    {...transaction1...},
    {...transaction2...}
  ]'
```

## ğŸ“‚ Project Structure

```
Fraud_Detection_System-main/
â”œâ”€â”€ alert_service/              # Alert management service
â”‚   â”œâ”€â”€ alert_app.py           # Flask app
â”‚   â”œâ”€â”€ notifier.py            # Alert notifier
â”‚   â””â”€â”€ fraud_alerts.json      # Alert logs
â”‚
â”œâ”€â”€ ml_service/                # ML scoring service
â”‚   â””â”€â”€ app.py                 # Flask endpoint
â”‚
â”œâ”€â”€ ml_model/                  # ML training pipeline
â”‚   â”œâ”€â”€ model_training.py      # Model trainer
â”‚   â”œâ”€â”€ feature_engineering.py # Feature transformer
â”‚   â”œâ”€â”€ evaluate_model.py      # Model evaluation
â”‚   â”œâ”€â”€ fraud_model.pkl        # Trained model (generated)
â”‚   â””â”€â”€ feature_engineer.pkl   # Feature engineer (generated)
â”‚
â”œâ”€â”€ kafka_streaming/           # Kafka producer/consumer
â”‚   â”œâ”€â”€ producer.py            # Transaction producer
â”‚   â””â”€â”€ consumer.py            # Stream consumer
â”‚
â”œâ”€â”€ spark_processing/          # Spark streaming job
â”‚   â””â”€â”€ spark_job.py           # Spark stream processor
â”‚
â”œâ”€â”€ web_ui/                    # Web dashboard
â”‚   â”œâ”€â”€ app.py                 # Flask app
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ index.html         # Dashboard UI
â”‚   â””â”€â”€ static/
â”‚       â”œâ”€â”€ css/
â”‚       â”‚   â””â”€â”€ dashboard.css
â”‚       â””â”€â”€ js/
â”‚           â””â”€â”€ dashboard.js
â”‚
â”œâ”€â”€ data/                      # Data generation
â”‚   â”œâ”€â”€ generate_data.py       # Synthetic data generator
â”‚   â”œâ”€â”€ sample_transactions.csv
â”‚   â””â”€â”€ raw/
â”‚       â”œâ”€â”€ transactions_train.csv (generated)
â”‚       â””â”€â”€ transactions_test.csv (generated)
â”‚
â”œâ”€â”€ docker/                    # Docker configurations
â”‚   â”œâ”€â”€ ml_service.Dockerfile
â”‚   â”œâ”€â”€ alert_service.Dockerfile
â”‚   â”œâ”€â”€ producer.Dockerfile
â”‚   â”œâ”€â”€ web_ui.Dockerfile
â”‚   â””â”€â”€ spark.Dockerfile
â”‚
â”œâ”€â”€ k8s/                       # Kubernetes configs (optional)
â”‚   â”œâ”€â”€ fraud-ml-service.yml
â”‚   â”œâ”€â”€ fraud-alert-service.yml
â”‚   â”œâ”€â”€ fraud-producer.yml
â”‚   â”œâ”€â”€ fraud-spark.yml
â”‚   â””â”€â”€ fraud-web-ui.yml
â”‚
â”œâ”€â”€ scripts/                   # Utility scripts
â”‚   â”œâ”€â”€ run_all.sh            # Start all services
â”‚   â”œâ”€â”€ stop_all.sh           # Stop all services
â”‚   â””â”€â”€ simulate_transactions.py # Test data generator
â”‚
â”œâ”€â”€ tests/                     # Unit tests
â”‚   â”œâ”€â”€ test_ml_service.py     # ML service tests
â”‚   â””â”€â”€ test_alert_service.py  # Alert service tests
â”‚
â”œâ”€â”€ docker-compose.yml         # Docker composition
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                  # This file
```

## ğŸ§ª Testing

### Run Unit Tests

```bash
pytest tests/
```

### Run with Coverage

```bash
pytest --cov=ml_service --cov=alert_service tests/
```

## ğŸ“Š Data Pipeline

### Transaction Features

The system generates and processes transactions with:

- **transaction_id**: Unique transaction identifier
- **amount**: Transaction amount ($)
- **amount_log**: Log-transformed amount
- **merchant_id**: Merchant identifier
- **user_id**: User identifier
- **latitude/longitude**: Transaction location
- **hour**: Hour of transaction (0-23)
- **day_of_week**: Day of week (0-6)
- **is_weekend**: Boolean flag
- **is_night**: Night-time flag (20:00-06:00)
- **transaction_type**: Type (online, in-store, ATM)
- **is_fraud**: Label (0=normal, 1=fraud)

### Model Features

The ML model uses 9 features after engineering:
1. amount
2. amount_log
3. latitude
4. longitude
5. hour
6. day_of_week
7. is_weekend
8. is_night
9. transaction_type_encoded

## ğŸ¯ Model Performance

- **Algorithm**: RandomForest Classifier
- **Class Imbalance Handling**: SMOTE
- **Training Data**: ~8,000 transactions
- **Fraud Ratio**: ~2%
- **Features**: 9 engineered features
- **Output**: Fraud probability (0-1)

### Risk Levels

- **LOW**: Fraud probability < 0.3
- **MEDIUM**: 0.3 â‰¤ Fraud probability < 0.7
- **HIGH**: Fraud probability â‰¥ 0.7

## ğŸ”§ Troubleshooting

### Port Already in Use

```bash
# Kill process on port
lsof -i :8000
kill -9 <PID>

# Restart services
./scripts/run_all.sh
```

### Model Not Found

```bash
# Regenerate training data and model
python data/generate_data.py
python ml_model/model_training.py
```

### Kafka Connection Issues

```bash
# Check Kafka container status
docker ps | grep kafka

# Restart Docker Compose
docker-compose restart kafka
```

### Service Health Check Failed

```bash
# Check individual service logs
curl http://localhost:5000/health
curl http://localhost:5001/health
curl http://localhost:8000/
```

## ğŸ“š Dependencies

- **Web Framework**: Flask, Flask-CORS
- **ML**: scikit-learn, pandas, numpy, joblib, imbalanced-learn
- **Streaming**: kafka-python, PySpark
- **Testing**: pytest
- **Utilities**: python-dotenv, matplotlib, seaborn

## ğŸ” Security Notes

- The system uses basic logging for alerts
- Consider implementing proper alerting/notification services
- For production, add authentication/authorization
- Encrypt sensitive data and API communications

## ğŸ“ License

MIT License - See LICENSE file for details

## ğŸ‘¥ Contributing

1. Create a feature branch
2. Commit your changes
3. Push to the branch
4. Create a Pull Request

## ğŸ“ Support

For issues and questions, please create an issue in the repository.

---

**Happy Fraud Detection! ğŸš€**
